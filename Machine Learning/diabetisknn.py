# -*- coding: utf-8 -*-
"""DiabetisKnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1u92p-jKoWu6ldK8hiXORNg2fjLq6vrJL
"""

# Load libraries
import pandas as pd
from sklearn.tree import DecisionTreeClassifier 
from sklearn.model_selection import train_test_split 
from sklearn.metrics import accuracy_score 
from sklearn import tree

from google.colab import drive
drive.mount('/content/drive')

# load dataset
pima = pd.read_csv("/content/drive/MyDrive/ML/Copy of diabetes.csv", encoding='utf8', engine='python')
drive.flush_and_unmount()

pima.head()

# feature selection
feature_cols = ['Pregnancies', 'Insulin', 'BMI', 'Age', 'Glucose', 'BloodPressure', 'DiabetesPedigreeFunction']
X = pima[feature_cols]
y = pima.Outcome

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 80% training and 20% test

from sklearn.neighbors import KNeighborsClassifier
KNN = KNeighborsClassifier(n_neighbors=5)
KNN.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix
Y_pred = KNN.predict(X_test)
#Accuray of the model 
print("Accuracy:", accuracy_score(y_test, Y_pred))
print(confusion_matrix(y_test, Y_pred))

error = []
import numpy as np

# Calculating error for K values between 1 and 40
for i in range(1, 40):
    knn = KNeighborsClassifier(n_neighbors=i)
    knn.fit(X_train, y_train)
    pred_i = knn.predict(X_test)
    error.append(np.mean(pred_i != y_test))
    print(np.mean(pred_i != y_test))

from matplotlib import pyplot as plt

plt.figure(figsize=(12, 6))
plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',
         markerfacecolor='blue', markersize=10)
plt.title('Error Rate K Value')
plt.xlabel('K Value')
plt.ylabel('Mean Error')

