# -*- coding: utf-8 -*-
"""CustomDataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xLij8npZGSSGcleJx78kfoKJtzZHVT_9

**DECISION TREE**
"""

import numpy as np 
import pandas as pd 
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix 
from sklearn.tree import DecisionTreeClassifier 
from sklearn.metrics import accuracy_score 
from matplotlib import pyplot as plt
from sklearn import tree

from google.colab import drive
drive.mount('/content/drive')

# load dataset
df = pd.read_csv("/content/drive/MyDrive/ML/Grade Prediction Data.csv", encoding='utf8', engine='python')

df.head()
#df.replace(np.nan,0)

drive.flush_and_unmount()

df = df.dropna()
df.info()

# feature selection
feature_cols = ['Daily Study Hour (0 - )', 'Average CT Marks (0 - 20)', 'Class Attendance (percentage)', 'PL/SPL Study Hours (Daily) (0 - )',
                'PL/SPL Sleeping Hours (Daily Average)', 'Average Sleeping Hours (Daily)', 'Social Media Hours (Daily Average)',
                'PL/SPL Social Media Hours (Daily Average)','Concentration in Classes (0 - 10)','Confidence (0 - 10)']
X = df[feature_cols].values.tolist()
y = df['Final Grade (last Semester - 3-2) (GPA) '].values.tolist()

print(X[0:5])
print(y[0:5])

for i in range(len(y)):
  if y[i]>=3.75:
    y[i]=6
  elif y[i]>= 3.5:
    y[i]=5
  elif y[i]>=3.25:
    y[i]=4
  elif y[i]>=3.0 :
    y[i]=3
  elif y[i]>=2.75 :
    y[i]=2
  elif y[i]>= 2.5:
    y[i]=1
  else:
    y[i]=0

print(y[0:5])

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # 80% training and 20% test

# Decision tree classifier 
DT = DecisionTreeClassifier(criterion='entropy')

#fitting the training data
DT.fit(X_train, y_train)

# prediction on random data
Y_pred=DT.predict(X_train)
print(Y_pred)

# prediction on X_test (testing data )
Y_pred=DT.predict(X_test)
print(Y_pred)

#Accuray of the model 
print("Accuracy:", accuracy_score(y_test, Y_pred))
#confusion matrix
cm=np.array(confusion_matrix(y_test, Y_pred))
cm

import graphviz 
dot_data = tree.export_graphviz(DT, out_file=None, 
                      feature_names=feature_cols,  
                      class_names=['0','1','2','3','4','5','6'],  
                      filled=True, rounded=True,  
                      special_characters=True)  
graph = graphviz.Source(dot_data)  
graph

"""KNN"""

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(X_train)

X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

from sklearn.neighbors import KNeighborsClassifier
KNN = KNeighborsClassifier(n_neighbors=5)
KNN.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix
Y_pred = KNN.predict(X_test)
#Accuray of the model 
print("Accuracy:", accuracy_score(y_test, Y_pred))
print(confusion_matrix(y_test, Y_pred))

error = []

# Calculating error for K values between 1 and 40
for i in range(1, 40):
    knn = KNeighborsClassifier(n_neighbors=i)
    knn.fit(X_train, y_train)
    pred_i = knn.predict(X_test)
    error.append(np.mean(pred_i != y_test))
    print(np.mean(pred_i != y_test))

plt.figure(figsize=(12, 6))
plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o',
         markerfacecolor='blue', markersize=10)
plt.title('Error Rate K Value')
plt.xlabel('K Value')
plt.ylabel('Mean Error')